# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fh-Ks72ySDGJ2aUau6UrQW7-xytDLSsm
"""

import numpy as np
import pandas  as pd
import math as m
import seaborn as sns
import matplotlib.pyplot as plt
from collections import Counter
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
import xgboost as xgb
from sklearn.ensemble import GradientBoostingClassifier
model = GradientBoostingClassifier()

df = pd.read_excel('/content/Personal Bank Loan Classification (1) (1) (1).xlsx', sheet_name='Data')
df.head(5)

df

df.info()

df.describe()

df.columns

df.isnull().sum()

df.duplicated().sum()

sns.boxplot(df['Age'])

sns.boxplot(df['Income'])

sns.boxplot(df['Experience'])

sns.boxplot(df['ZIP Code'])

sns.barplot(df['ZIP Code'])

df

df.rename(columns={'CCAvg': 'CAI'}, inplace=True)

df

sns.boxplot(df['CAI'])

df.info()

df.drop(columns=['ID'], inplace=True)

df.drop(columns=['Family'], inplace=True)

df

df_log = df.apply(lambda x: np.log1p(x) if np.issubdtype(x.dtype, np.number) else x)

# Plot box plots for log-transformed data
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_log)

# Add title
plt.title("Box Plot for Log-Transformed Numerical Columns")

# Show plot
plt.xticks(rotation=45)  # Rotate labels if needed
plt.show()

sns.boxplot(df['Income'])

Q1 = df.quantile(0.25)

Q3 = df.quantile(0.75)

IQR = Q3 - Q1

ll = Q1 - 1.5 * IQR

ul = Q3 + 1.5 * IQR

df_new = df[((df < ll) | (df > ul)).any(axis=1)]

sns.boxplot(df_new['Income'])

sns.boxplot(df['CAI'])

Q1 = df.quantile(0.25)

Q3 = df.quantile(0.75)

IQR = Q3 - Q1

ll = Q1 - 1.5 * IQR

ul = Q3 + 1.5 * IQR

df_new = df[((df < ll) | (df > ul)).any(axis=1)]

sns.boxplot(df_new['CAI'])

sns.boxplot(df['Personal Loan'])

sns.boxplot(df['Age'])

sns.violinplot(df['CAI'])

sns.countplot(df['Personal Loan'])

sns.violinplot(df['Personal Loan'])

sns.boxplot(df['Securities Account'])

sns.boxplot(df['CD Account'])

sns.violinplot(df['CD Account'])

df_log = df.apply(lambda x: np.log1p(x) if np.issubdtype(x.dtype, np.number) else x)

# Plot box plots for log-transformed data
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_log)

# Add title
plt.title("Box Plot for Log-Transformed Numerical Columns")

# Show plot
plt.xticks(rotation=45)  # Rotate labels if needed
plt.show()



credit_card_counts = df['CreditCard'].value_counts()

# Create a pie chart
plt.figure(figsize=(6,6))
plt.pie(credit_card_counts, labels=credit_card_counts.index, autopct='%1.1f%%', colors=['lightblue', 'orange'])

# Add a title
plt.title('Credit Card Ownership Distribution')

# Show the chart
plt.show()

sns.kdeplot(df['Personal Loan'])

sns.boxplot(data=df, x='Personal Loan',y='Securities Account')

df

sns.kdeplot(df['Securities Account'])

sns.histplot(data=df, x='Income', bins=30, kde=True)
plt.show()

sns.histplot(data=df, x='Age', bins=30, kde=True)
plt.show()

sns.kdeplot(df['Personal Loan'])

# Create the count plot
plt.figure(figsize=(8,5))
sns.countplot(data=df, x='Education', palette='viridis')

# Add labels and title
plt.xlabel("Education Level")
plt.ylabel("Count")
plt.title(" univarient Distribution of Education Levels")

# Rotate x-axis labels if needed
plt.xticks(rotation=30)

# Show the plot
plt.show()

sns.violinplot(df['CreditCard'])

plt.figure(figsize=(6, 4))

# Create count plot
sns.countplot(data=df, x='Personal Loan', palette='coolwarm')

# Add labels and title
plt.xlabel("Personal Loan")
plt.ylabel("Count")
plt.title("Distribution of Personal Loan Approvals")

# Show the plot
plt.show()

plt.figure(figsize=(7,5))
sns.countplot(data=df, x='CreditCard', hue='Income', palette='coolwarm')

# Add labels and title
plt.xlabel("Credit Card Ownership (0 = No, 1 = Yes)")
plt.ylabel("Count")
plt.title("Credit Card Ownership Distribution by Default Status")

# Show the plot
plt.show()

# Set the style for better visualization
sns.set_style("whitegrid")

# Create a scatter plot using seaborn
plt.figure(figsize=(8, 6))

# Assuming 'Personal Loan' column contains 0 and 1
# Change palette to map 'Personal Loan' values correctly:
sns.scatterplot(x=df["Income"], y=df["Experience"],palette={0: "red", 1: "green"}, alpha=0.6)

# Labels & title
plt.xlabel("Income")
plt.title("Bivariate Scatter Plot: Income vs. Personal Loan")

# Show plot
plt.show()

df.info()

plt.figure(figsize=(8, 6))
sns.histplot(x=df['Experience'], y=df['Income'], bins=10, cmap="Blues")
# Labels and title
plt.xlabel("Number of Credit Cards")
plt.ylabel("Income ($1000s)")
plt.title("Bivariate Histogram: Credit Cards vs Income")

# Show the plot
plt.show()

# Create a bar plot
plt.figure(figsize=(8, 6))
sns.barplot(x=df['CD Account'], y=df['Income'], data=df, estimator=sum, palette="Blues")

# Labels and title
plt.xlabel("CD Account Ownership")
plt.ylabel("Total Income ($1000s)")
plt.title("Bar Plot: CD Account vs Income")

# Show the plot
plt.show()

df = df.rename(columns={'Securities Account': 'SA', })

df.info()

# Compute correlation matrix
corr_matrix = df.corr()

# Plot heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()

df.drop(column=['Age'],inplace=True)

df.info()

df.drop(columns=['ZIP Code'], inplace=True)

df.info()

df

print(df['Personal Loan'].value_counts())

# Separate features and target
X = df.drop(columns=['Personal Loan'])  # Drop 'Personal Loan' column to keep features
y = df['Personal Loan']  # Target variable


# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Apply SMOTE to balance the classes
smote = SMOTE(sampling_strategy='auto', random_state=42)
X_resampled, y_resampled = smote.fit_resample(X_train, y_train)

# Check new class distribution
print(pd.Series(y_resampled).value_counts())

# Separate features and target
X = df.drop(columns=['Personal Loan'])  # Independent Variables
y = df['Personal Loan']  # Target Variable

df.info()

X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

print("Training set shape:", X_train.shape)
print("Testing set shape:", X_test.shape)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

model = LogisticRegression()
model.fit(X_resampled, y_resampled)

y_pred = model.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

y_pred = model.predict(X_train)

print("Accuracy:", accuracy_score(y_train, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_train, y_pred))
print("\nClassification Report:\n", classification_report(y_train, y_pred))

k = 5  # Choose the number of neighbors
knn = KNeighborsClassifier(n_neighbors=k)
knn.fit(X_train, y_train)

y_pred = knn.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

y_pred = knn.predict(X_train)

svc = SVC(kernel='linear', C=1.0)  # Using a linear kernel
svc.fit(X_train, y_train)

y_pred = svc.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

y_pred = svc.predict(X_train)

print("Accuracy:", accuracy_score(y_train, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_train, y_pred))
print("\nClassification Report:\n", classification_report(y_train, y_pred))

dt = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=42)
dt.fit(X_train, y_train)

y_pred = dt.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

y_pred = dt.predict(X_train)

print("Accuracy:", accuracy_score(y_train, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_train, y_pred))
print("\nClassification Report:\n", classification_report(y_train, y_pred))

plt.figure(figsize=(12, 9))
plot_tree(dt, feature_names=X.columns, class_names=['No Credit Card', 'Has Credit Card'], filled=True)
plt.show()

rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

y_pred = rf.predict(X_train)

print("Accuracy:", accuracy_score(y_train, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_train, y_pred))
print("\nClassification Report:\n", classification_report(y_train, y_pred))

model.fit(X_test, y_test)

y_pred = rf.predict(X_train)

print("Accuracy:", accuracy_score(y_train, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_train, y_pred))
print("\nClassification Report:\n", classification_report(y_train, y_pred))

y_pred = rf.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

(y_resampled)

df.info()

cm = confusion_matrix(y_test, y_pred)

# Plot Confusion Matrix Heatmap
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=["No Credit Card", "Has Credit Card"],
            yticklabels=["No Credit Card", "Has Credit Card"])
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix Heatmap")
plt.show()

# Print Performance Metrics
print("Accuracy Score:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

# Define AdaBoost model
AdaBoost = AdaBoostClassifier(
    n_estimators=100,  # Number of boosting rounds
    learning_rate=1.0,
    random_state=42
)

# Train the model
AdaBoost.fit(X_train, y_train)

# Make predictions
y_pred = AdaBoost.predict(X_test)
from sklearn.metrics import accuracy_score, classification_report

# Assuming y_test and y_pred are defined
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Test Accuracy:", accuracy)
print("Classification Report:\n", report)

# Define XGBoost model
xgb_model = xgb.XGBClassifier(
    n_estimators=100,  # Number of boosting rounds
    learning_rate=0.1,  # Learning rate
    max_depth=3,  # Depth of trees
    random_state=42
)

# Train the model
xgb_model.fit(X_train, y_train)

# Make predictions
y_pred = xgb_model.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report

# Assuming y_test and y_pred are defined
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Test Accuracy:", accuracy)
print("Classification Report:\n", report)

# Define Gradient Boosting Classifier model
gbc_model = GradientBoostingClassifier(
    n_estimators=100,  # Number of boosting rounds
    learning_rate=0.1,  # Learning rate
    max_depth=3,  # Depth of trees
    random_state=42
)

# Train the model
gbc_model.fit(X_train, y_train)

# Make predictions
y_pred = gbc_model.predict(X_test)

# Evaluate model performance
accuracy = accuracy_score(y_test, y_pred)
print("Test Accuracy:", accuracy)

# Assuming y_test and y_pred are defined
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print("Test Accuracy:", accuracy)
print("Classification Report:\n", report)

"""this is our best model"""